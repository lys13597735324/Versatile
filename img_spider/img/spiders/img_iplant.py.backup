import json
import re
import requests

from scrapy import Spider, Request
from pyquery import PyQuery as pq
from ..items import ImgItem
from ..get_words import read_keywords_list
from json import loads
import urllib.parse


class ImgspiderSpider(Spider):
    name = "img_iplant"

    def __init__(self, *args, **kwargs):
        self.allowed_domains = ["iplant.cn"]

    def start_requests(self):
        keywords = read_keywords_list()
        # keywords = ['樟', '银杏']
        pages = 100

        for keyword in keywords:
            url_cid = 'http://ppbc.iplant.cn/list?keyword={}'.format(keyword)
            resp = requests.get(url_cid)
            pattern = re.compile(r';cid=(.*?)"')
            cid = re.findall(pattern, resp.text)
            if len(cid) == 1:
                cid = cid[0]
                for page_num in range(1, pages):

                    url = 'http://ppbc.iplant.cn/ashx/getphotopage.ashx?page={page}&n=2&group=sp&cid={cid}'.format(page=page_num, cid=cid)
                    print(url)


                    yield Request(url=url, callback=self.parse)

    def parse(self, response):
        pattern = re.compile(r"' src='(.*?)' />")
        url_list = re.findall(pattern, response.text)
        img_item = ImgItem()
        for i in url_list:
            img_url = 'http://img1.iplant.cn/image2/b/' + i.split('/')[-1]
            img_item['img_url'] = img_url
            # print(img_url)
            img_item['img_website'] = self.name.split('_')[-1]
            img_item['img_name'] = img_url.split('/')[-1]
            yield img_item
